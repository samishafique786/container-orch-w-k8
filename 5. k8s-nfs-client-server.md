# NFS Server and Client Setup for Kubernetes

## Introduction

In this guide, we'll walk through the process of setting up an NFS server to store databases and files outside the Kubernetes cluster, and configuring NFS client on Kubernetes nodes to access the NFS share.

## NFS Server Setup

1. Install NFS Server on the Load Balancer VM

```bash
sudo apt install nfs-kernel-server
```
2. Create an NFS export directory and remove any restrictions in the directory permissions.
```bash
sudo mkdir -p /mnt/nfs_share
sudo chown -R nobody:nogroup /mnt/nfs_share/
sudo chmod 777 /mnt/nfs_share/
```

3. Grant NFS share access to client systems:
```bash
sudo vim /etc/exports
```
Add the following line to the file, replacing 192.168.1.0/24 with the public subnet of your client systems:

```/mnt/nfs_share 192.168.1.0/24(rw,sync,no_subtree_check)```

Save the file and exit the editor.

4. Export the NFS share directory:
```bash
sudo exportfs -a
```
5. Restart the NFS kernel server:
```bash
sudo systemctl restart nfs-kernel-server
```

## NFS Client Setup



### Step 2: Install NFS Client on Kubernetes Nodes

1. SSH into each Kubernetes node.
2. Install NFS client packages:
   ```bash
   sudo apt update
   sudo apt install nfs-common
   ```
3. Create an NFS Mount Point on Client
```bash
sudo mkdir -p /mnt/nfs_clientshare
```
4. Mount NFS Share on Client System

Head back to your load-balancer VM, and check the IP of the public network, in my case, 192.168.1.18, and mount the NFS Share on the node.
```bash
sudo mount 192.168.1.18:/mnt/nfs_share  /mnt/nfs_clientshare
```

5. Testing the NFS Share 
Now, verify that the NFS Share has been mounted. Head back to the NFS Server VM, create a couple for files in the directory.
```bash
cd /mnt/nfs_share/
touch file1.txt file2.txt file3.txt
```
Now, head back to the node(aka the client VMs), and check if you can see the created files.
```bash
ls -l /mnt/nfs_clientshare/
```
This process is successful if you can see the files in the clients' systems. 
